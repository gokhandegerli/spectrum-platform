# ğŸŒˆ Spectrum Platform - KapsamlÄ± Teknik DokÃ¼mantasyon

> **Production-Ready Mikroservis Mimarisi ile Ã–zel Layer 7 Load Balancer**

## ğŸ“‘ Ä°Ã§indekiler

1. [Proje Genel BakÄ±ÅŸ](#proje-genel-bakÄ±ÅŸ)
2. [Mimari YapÄ±](#mimari-yapÄ±)
3. [Dosya ve KlasÃ¶r YapÄ±sÄ±](#dosya-ve-klasÃ¶r-yapÄ±sÄ±)
4. [KonfigÃ¼rasyon DosyalarÄ±](#konfigÃ¼rasyon-dosyalarÄ±)
5. [Load Balancer DetaylÄ± Analiz](#load-balancer-detaylÄ±-analiz)
6. [Servisler](#servisler)
7. [Test ve Ã‡alÄ±ÅŸtÄ±rma](#test-ve-Ã§alÄ±ÅŸtÄ±rma)
8. [DeÄŸiÅŸiklik SenaryolarÄ±](#deÄŸiÅŸiklik-senaryolarÄ±)
9. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Proje Genel BakÄ±ÅŸ

**Spectrum Platform**, modern mikroservis mimarisinin tÃ¼m best practice'lerini iÃ§eren, production-ready bir ekosistemdir.

### Temel Ã–zellikler

- âœ… **Ã–zel Layer 7 Load Balancer** - Circuit breaker, rate limiting, multiple stratejiler
- âœ… **Mikroservis Architecture** - Ä°ki Ã¶rnek servis (Kisakes, Dummy Service)
- âœ… **Full Observability Stack** - Prometheus, Grafana, Loki, Promtail
- âœ… **Database Layer** - PostgreSQL 16 + Redis 7 caching
- âœ… **Containerized** - Docker Compose ile tam orkestrasyon
- âœ… **Production Features** - Health checks, metrics, tracing, structured logging

### Teknoloji Stack

```
Language:       Java 21 (Eclipse Temurin)
Framework:      Spring Boot 3.3.0
Build:          Maven 3.8+
Database:       PostgreSQL 16
Cache:          Redis 7
Migration:      Liquibase 4.28
Container:      Docker & Docker Compose
Monitoring:     Prometheus + Grafana
Logging:        Loki + Promtail
Tracing:        Micrometer Tracing (Brave)
```

---

## ğŸ—ï¸ Mimari YapÄ±

### Genel AkÄ±ÅŸ

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       Client/User               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Load Balancer (Port 8080)     â”‚
                    â”‚   - Circuit Breaker             â”‚
                    â”‚   - Rate Limiting               â”‚
                    â”‚   - Health Checking             â”‚
                    â”‚   - Multiple Strategies         â”‚
                    â”‚   - Sticky Sessions             â”‚
                    â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚                     â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Kisakes Service    â”‚   â”‚   Dummy Service       â”‚
       â”‚   - Instance 1:8081  â”‚   â”‚   - Instance 1:8083   â”‚
       â”‚   - Instance 2:8082  â”‚   â”‚   - Instance 2:8084   â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Data Layer         â”‚
    â”‚  - PostgreSQL       â”‚
    â”‚  - Redis Cache      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      Observability Stack                â”‚
    â”‚  - Prometheus (metrics)                 â”‚
    â”‚  - Grafana (visualization)              â”‚
    â”‚  - Loki (log aggregation)               â”‚
    â”‚  - Promtail (log collection)            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Port Mapping

| Service          | Internal Port | External Port | AÃ§Ä±klama                    |
|------------------|---------------|---------------|-----------------------------|
| Load Balancer    | 8080          | 8080          | Ana giriÅŸ noktasÄ±          |
| Kisakes App 1    | 8081          | -             | Sadece internal            |
| Kisakes App 2    | 8082          | -             | Sadece internal            |
| Dummy Service 1  | 8083          | -             | Sadece internal            |
| Dummy Service 2  | 8084          | -             | Sadece internal            |
| PostgreSQL       | 5432          | 5432          | Database access            |
| Redis            | 6379          | 6379          | Cache access               |
| Prometheus       | 9090          | 9090          | Metrics UI                 |
| Grafana          | 3000          | 3000          | Dashboard UI               |
| Loki             | 3100          | 3100          | Log API                    |

---

## ğŸ“‚ Dosya ve KlasÃ¶r YapÄ±sÄ±

### Root Level

```
spectrum-platform/
â”œâ”€â”€ docker-compose.yml          # Ana orkestrasyon dosyasÄ±
â”œâ”€â”€ pom.xml                     # Parent Maven POM
â”œâ”€â”€ settings.xml                # Maven settings
â”œâ”€â”€ qodana.yaml                 # Code quality config
â”œâ”€â”€ README.md                   # Proje dokÃ¼mantasyonu
â”œâ”€â”€ services/                   # Mikroservisler
â”œâ”€â”€ infrastructure/             # AltyapÄ± bileÅŸenleri
â”œâ”€â”€ scripts/                    # Otomasyon scriptleri
â”œâ”€â”€ docs/                       # DokÃ¼mantasyon
â”œâ”€â”€ examples/                   # Ã–rnek kullanÄ±mlar
â””â”€â”€ logs/                       # Log dosyalarÄ±
```

---

## ğŸ“‹ KonfigÃ¼rasyon DosyalarÄ±

### 1. docker-compose.yml

**AmaÃ§**: TÃ¼m servisleri orkestre eder, network ve volume yÃ¶netimini saÄŸlar.

**KullanÄ±m AlanlarÄ±**:
- Servis tanÄ±mlarÄ± ve baÄŸÄ±mlÄ±lÄ±klarÄ±
- Environment variable'lar
- Port mapping
- Health check tanÄ±mlarÄ±
- Volume mount'larÄ±

**DeÄŸiÅŸtirmen Gereken Durumlar**:
1. **Yeni servis eklerken**:
```yaml
  my-new-service:
    build:
      context: .
      dockerfile: services/my-new-service/Dockerfile
    container_name: my-new-service
    networks:
      - microservices-net
    expose:
      - "8085"
    environment:
      - SERVER_PORT=8085
```

2. **Port deÄŸiÅŸtirirken**:
```yaml
ports:
  - "9090:8080"  # External:Internal
```

3. **Environment variable eklerken**:
```yaml
environment:
  - NEW_CONFIG=value
  - API_KEY=${API_KEY:-default}
```

**Test Etmen Gerekenler**:
- `docker-compose config` - Syntax kontrolÃ¼
- `docker-compose up` - Servis baÅŸlatma
- `./scripts/health-check.sh` - Health check

---

### 2. Load Balancer Configuration

**Dosya**: `infrastructure/load-balancer/src/main/resources/application.yml`

**Kritik KonfigÃ¼rasyonlar**:

#### a) Load Balancing AlgoritmasÄ±
```yaml
loadbalancer:
  algorithm: ROUND_ROBIN  # DeÄŸiÅŸtirilebilir: LEAST_CONNECTIONS, WEIGHTED_ROUND_ROBIN, IP_HASH, RANDOM
```

**Ne Zaman DeÄŸiÅŸtirirsin**:
- ROUND_ROBIN: EÅŸit daÄŸÄ±lÄ±m istediÄŸinde (default)
- LEAST_CONNECTIONS: Servislerde farklÄ± iÅŸlem sÃ¼releri varsa
- WEIGHTED_ROUND_ROBIN: FarklÄ± kapasiteli sunucular varsa
- IP_HASH: Session persistence istediÄŸinde
- RANDOM: Basit daÄŸÄ±lÄ±m yeterli ise

**Test**:
```bash
# Load test ile daÄŸÄ±lÄ±mÄ± kontrol et
./scripts/load-test.sh http://localhost:8080/kisakes/actuator/health 100 10

# Admin API'den istatistikleri gÃ¶r
curl http://localhost:8080/admin/status | jq
```

#### b) Health Check Configuration
```yaml
loadbalancer:
  health-check-enabled: true
  health-check-interval: 5000    # 5 saniye
  health-check-timeout: 2000     # 2 saniye
```

**DeÄŸiÅŸtirme SenaryolarÄ±**:
- YavaÅŸ servisler: timeout'u artÄ±r
- HÄ±zlÄ± fail-over: interval'i azalt
- Devre dÄ±ÅŸÄ± bÄ±rakma: enabled: false

**Test**:
```bash
# Bir servisi kapat ve load balancer'Ä±n tepkisini izle
docker stop kisakes-app-2
./scripts/health-check.sh
# 5 saniye sonra load balancer bu instance'Ä± devre dÄ±ÅŸÄ± bÄ±rakÄ±r
```

#### c) Circuit Breaker
```yaml
loadbalancer:
  circuit-breaker:
    enabled: true
    failure-threshold: 5           # 5 baÅŸarÄ±sÄ±z istek sonrasÄ± aÃ§
    success-threshold: 2           # 2 baÅŸarÄ±lÄ± istek sonrasÄ± kapat
    timeout-seconds: 60            # AÃ§Ä±k kalma sÃ¼resi
    reset-timeout-seconds: 300     # SÄ±fÄ±rlama sÃ¼resi
```

**KullanÄ±m SenaryolarÄ±**:
- Bir servis sÃ¼rekli fail ediyorsa otomatik devre dÄ±ÅŸÄ± bÄ±rakÄ±r
- Cascade failure'Ä± Ã¶nler
- Servis recover olunca otomatik tekrar devreye alÄ±r

**Test**:
```bash
# Circuit breaker'Ä± test et
# 1. Bir servisi yavaÅŸlat veya hata dÃ¶ndÃ¼rmesini saÄŸla
# 2. SÃ¼rekli istek gÃ¶nder
for i in {1..10}; do
  curl http://localhost:8080/kisakes/api/endpoint
done

# 3. Circuit breaker state'ini kontrol et
curl http://localhost:8080/admin/circuit-breaker-status | jq
```

#### d) Rate Limiting
```yaml
loadbalancer:
  rate-limit:
    enabled: false  # Production'da true yap
```

**Aktif Etme**:
```yaml
loadbalancer:
  rate-limit:
    enabled: true
    requests-per-second: 100
    burst-capacity: 200
```

**Test**:
```bash
# Rate limit test
./scripts/load-test.sh http://localhost:8080/dummy-service/hello 1000 100
# 100 req/s'den fazla gelirse 429 Too Many Requests dÃ¶necek
```

#### e) Upstream (Backend) Servisleri
```yaml
loadbalancer:
  services:
    kisakes:
      algorithm: ROUND_ROBIN
      upstreams:
        - url: http://kisakes-app-1:8081
          weight: 1                  # Weighted algoritma iÃ§in
          max-connections: 100       # Connection pool
        - url: http://kisakes-app-2:8082
          weight: 2                  # Bu instance 2x daha fazla trafik alÄ±r
          max-connections: 100
```

**Yeni Upstream Ekleme**:
```yaml
- url: http://kisakes-app-3:8085
  weight: 1
  max-connections: 150
```

**Test SÃ¼reci**:
1. `docker-compose.yml`'de yeni instance ekle
2. `application.yml`'de upstream ekle
3. Rebuild: `docker-compose build load-balancer`
4. Restart: `docker-compose restart load-balancer`
5. Test: `./scripts/health-check.sh`

#### f) SSL/TLS Configuration
```yaml
loadbalancer:
  ssl:
    enabled: false  # Production'da true
```

**SSL Aktif Etme**:
```yaml
loadbalancer:
  ssl:
    enabled: true
    key-store: classpath:keystore.p12
    key-store-password: ${SSL_PASSWORD}
    key-store-type: PKCS12
```

**Test**:
```bash
# HTTPS test
curl -k https://localhost:8443/actuator/health
```

#### g) Sticky Sessions
```yaml
loadbalancer:
  sticky-session:
    enabled: false
```

**Ne Zaman KullanÄ±lÄ±r**:
- Session-based uygulamalar
- WebSocket connections
- Upload/download iÅŸlemleri

**Aktif Etme**:
```yaml
loadbalancer:
  sticky-session:
    enabled: true
    cookie-name: LB_SESSION
    cookie-max-age: 3600
```

---

### 3. Kisakes Service Configuration

**Dosya**: `services/kisakes/src/main/resources/application.yml`

```yaml
spring:
  application:
    name: kisakes
  
  datasource:
    url: ${DATABASE_URL:jdbc:postgresql://localhost:5432/kisakes}
    username: ${DATABASE_USERNAME:user}
    password: ${DATABASE_PASSWORD:password}
  
  data:
    redis:
      host: ${REDIS_HOST:localhost}
      port: ${REDIS_PORT:6379}
  
  liquibase:
    enabled: ${SPRING_LIQUIBASE_ENABLED:true}
    change-log: classpath:db/changelog/db.changelog-master.yaml

server:
  port: ${SERVER_PORT:8080}
```

**Environment-Specific Overrides**:

**application-docker.yml**:
```yaml
spring:
  datasource:
    url: jdbc:postgresql://postgres-db:5432/kisakes
```

**DeÄŸiÅŸiklik SenaryolarÄ±**:

1. **Database DeÄŸiÅŸtirme**:
```yaml
spring:
  datasource:
    url: jdbc:mysql://mysql-db:3306/kisakes
    driver-class-name: com.mysql.cj.jdbc.Driver
```
**Test**: 
- `docker-compose restart kisakes-app-1 kisakes-app-2`
- Log kontrolÃ¼: `docker logs kisakes-app-1`

2. **Redis Åifre Ekleme**:
```yaml
spring:
  data:
    redis:
      password: ${REDIS_PASSWORD}
```
**Test**: 
- Redis'e manuel baÄŸlan: `redis-cli -h localhost -p 6379 -a mypassword`

3. **Liquibase Disable Etme** (2. instance'da):
```yaml
spring:
  liquibase:
    enabled: false
```

---

### 4. Database Migration (Liquibase)

**Dosya**: `services/kisakes/src/main/resources/db/changelog/db.changelog-master.yaml`

```yaml
databaseChangeLog:
  - include:
      file: db/changelog/changes/001-create-urls-table.yaml
  - include:
      file: db/changelog/changes/002-create-short-code-lookup-table.yaml
```

**Yeni Migration Ekleme**:
1. Yeni dosya oluÅŸtur: `003-add-new-column.yaml`
```yaml
databaseChangeLog:
  - changeSet:
      id: 003-add-new-column
      author: yourname
      changes:
        - addColumn:
            tableName: urls
            columns:
              - column:
                  name: new_column
                  type: varchar(255)
```

2. Master'a ekle:
```yaml
  - include:
      file: db/changelog/changes/003-add-new-column.yaml
```

3. Test:
```bash
# Restart ile migration Ã§alÄ±ÅŸÄ±r
docker-compose restart kisakes-app-1

# Database'i kontrol et
docker exec -it postgres-db psql -U admin -d kisakes
\d urls
```

---

### 5. Monitoring Configurations

#### Prometheus (`infrastructure/monitoring/prometheus/prometheus.yml`)

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'load-balancer'
    static_configs:
      - targets: ['load-balancer:8080']
    metrics_path: '/actuator/prometheus'
  
  - job_name: 'kisakes'
    static_configs:
      - targets: ['kisakes-app-1:8081', 'kisakes-app-2:8082']
    metrics_path: '/actuator/prometheus'
```

**Yeni Servis Ekleme**:
```yaml
  - job_name: 'my-new-service'
    static_configs:
      - targets: ['my-service-1:8085', 'my-service-2:8086']
    metrics_path: '/actuator/prometheus'
```

**Test**:
```bash
# Prometheus targets'Ä± kontrol et
open http://localhost:9090/targets
```

#### Loki (`infrastructure/monitoring/loki/loki-config.yml`)

Log aggregation konfigÃ¼rasyonu. Genellikle deÄŸiÅŸtirilmez.

#### Promtail (`infrastructure/monitoring/promtail/promtail-config.yml`)

Docker container loglarÄ±nÄ± toplar. Default yapÄ±landÄ±rma yeterlidir.

---

## ğŸ”§ Load Balancer DetaylÄ± Analiz

### Java SÄ±nÄ±flarÄ± ve GÃ¶revleri

#### 1. **LoadBalancerApplication.java**
- **AmaÃ§**: Spring Boot ana uygulama sÄ±nÄ±fÄ±
- **DeÄŸiÅŸtirme**: Gerekli deÄŸil
- **Test**: `mvn spring-boot:run` ile lokal Ã§alÄ±ÅŸtÄ±r

#### 2. **ProxyController.java**
- **AmaÃ§**: Gelen istekleri backend servislerine yÃ¶nlendirir
- **Endpoint**: `/**` (catch-all)
- **MantÄ±k**:
  1. Request'i yakalar
  2. Service registry'den backend seÃ§er
  3. Load balancing stratejisi uygular
  4. Circuit breaker kontrolÃ¼ yapar
  5. Backend'e forward eder
  6. Response'u dÃ¶ner

**DeÄŸiÅŸtirme Senaryosu - Custom Header Ekleme**:
```java
@RestController
public class ProxyController {
    
    @RequestMapping("/**")
    public ResponseEntity<?> proxyRequest(HttpServletRequest request) {
        // Custom header ekle
        HttpHeaders headers = new HttpHeaders();
        headers.add("X-Forwarded-By", "Spectrum-LB");
        
        // ... existing code ...
    }
}
```

**Test**:
```bash
curl -v http://localhost:8080/kisakes/actuator/health
# Header'Ä± gÃ¶receksin: X-Forwarded-By: Spectrum-LB
```

#### 3. **AdminController.java**
- **AmaÃ§**: Admin API'leri (monitoring, management)
- **Endpoints**:
  - `GET /admin/status` - Servis durumlarÄ±
  - `GET /admin/features` - Aktif Ã¶zellikler
  - `POST /admin/circuit-breaker/reset` - Circuit breaker sÄ±fÄ±rla
  - `POST /admin/servers/{service}/add` - Dinamik backend ekleme
  - `DELETE /admin/servers/{service}/{url}` - Backend kaldÄ±rma

**KullanÄ±m**:
```bash
# Durum kontrolÃ¼
curl http://localhost:8080/admin/status | jq

# Dinamik backend ekleme
curl -X POST http://localhost:8080/admin/servers/kisakes/add \
  -H "Content-Type: application/json" \
  -d '{"url":"http://kisakes-app-3:8085", "weight":1, "maxConnections":100}'

# Circuit breaker sÄ±fÄ±rlama
curl -X POST http://localhost:8080/admin/circuit-breaker/reset
```

#### 4. **ServiceRegistry.java**
- **AmaÃ§**: Backend servis listesini yÃ¶netir
- **Fonksiyonlar**:
  - Backend listesi tutma
  - Health status takibi
  - Dinamik ekleme/Ã§Ä±karma

**DeÄŸiÅŸtirme - Service Discovery Entegrasyonu**:
```java
@Component
public class ServiceRegistry {
    
    // Consul/Eureka entegrasyonu iÃ§in
    public void discoverServices() {
        // Consul API'den servisleri Ã§ek
        // Registry'e ekle
    }
}
```

#### 5. **HealthChecker.java**
- **AmaÃ§**: Backend servislerinin health check'ini yapar
- **MantÄ±k**:
  - Her N saniyede backend'lere health check yapar
  - Unhealthy olanlarÄ± devre dÄ±ÅŸÄ± bÄ±rakÄ±r
  - Recover olanlarÄ± tekrar devreye alÄ±r

**DeÄŸiÅŸtirme - Custom Health Check**:
```java
@Component
public class HealthChecker {
    
    @Scheduled(fixedDelayString = "${loadbalancer.health-check-interval}")
    public void checkHealth() {
        for (Server server : servers) {
            boolean healthy = customHealthCheck(server);
            server.setHealthy(healthy);
        }
    }
    
    private boolean customHealthCheck(Server server) {
        // Custom logic: database baÄŸlantÄ±sÄ±, disk alanÄ± vb.
        return checkDatabase(server) && checkDiskSpace(server);
    }
}
```

#### 6. **Load Balancing Strategies**

##### a) **RoundRobinStrategy.java**
- SÄ±rayla daÄŸÄ±tÄ±m
- En basit ve yaygÄ±n

##### b) **LeastConnectionsStrategy.java**
- En az aktif baÄŸlantÄ±sÄ± olan servise yÃ¶nlendirir
- FarklÄ± iÅŸlem sÃ¼reli istekler iÃ§in ideal

##### c) **WeightedRoundRobinStrategy.java**
- AÄŸÄ±rlÄ±ÄŸa gÃ¶re daÄŸÄ±tÄ±m
- FarklÄ± kapasiteli sunucular iÃ§in

##### d) **IpHashStrategy.java**
- Client IP'sine gÃ¶re consistent hashing
- Session persistence saÄŸlar

##### e) **RandomStrategy.java**
- Random daÄŸÄ±tÄ±m

**Yeni Strateji Ekleme**:
```java
@Component
public class CustomStrategy implements LoadBalancingStrategy {
    
    @Override
    public Server selectServer(List<Server> servers, HttpServletRequest request) {
        // Custom logic
        // Ã–rnek: Header'a gÃ¶re routing
        String priority = request.getHeader("X-Priority");
        if ("high".equals(priority)) {
            return getHighPriorityServer(servers);
        }
        return getDefaultServer(servers);
    }
}
```

**KullanÄ±m**:
```yaml
loadbalancer:
  algorithm: CUSTOM
```

```java
@Component
public class LoadBalancingStrategyFactory {
    
    public LoadBalancingStrategy getStrategy(String algorithm) {
        return switch (algorithm) {
            case "ROUND_ROBIN" -> new RoundRobinStrategy();
            case "CUSTOM" -> new CustomStrategy();
            // ...
        };
    }
}
```

#### 7. **CircuitBreaker.java**
- **AmaÃ§**: Cascade failure Ã¶nleme
- **States**: CLOSED, OPEN, HALF_OPEN
- **MantÄ±k**:
  - CLOSED: Normal Ã§alÄ±ÅŸma
  - OPEN: Threshold aÅŸÄ±ldÄ±, istekler hemen fail
  - HALF_OPEN: Test aÅŸamasÄ±, baÅŸarÄ±lÄ± olursa CLOSED'a dÃ¶ner

**DeÄŸiÅŸtirme - Custom Failure Detection**:
```java
public class CircuitBreaker {
    
    public void recordFailure() {
        failureCount++;
        
        // Custom: belirli hata kodlarÄ± iÃ§in farklÄ± davran
        if (is5xxError()) {
            failureCount += 2; // 5xx hatalarÄ± daha aÄŸÄ±r bas
        }
        
        if (failureCount >= failureThreshold) {
            state = State.OPEN;
        }
    }
}
```

#### 8. **RateLimiter.java**
- **AmaÃ§**: Rate limiting (DDoS korumasÄ±)
- **Algoritma**: Token Bucket veya Sliding Window

**Token Bucket MantÄ±ÄŸÄ±**:
```
Bucket Capacity: 100 token
Refill Rate: 10 token/second

Ä°stek geldiÄŸinde:
- 1 token tÃ¼ket
- Token yoksa 429 dÃ¶ner
- Her saniye bucket'a 10 token eklenir
```

**DeÄŸiÅŸtirme - Per-User Rate Limiting**:
```java
public class RateLimiter {
    
    private Map<String, TokenBucket> userBuckets = new ConcurrentHashMap<>();
    
    public boolean allowRequest(HttpServletRequest request) {
        String userId = request.getHeader("X-User-ID");
        TokenBucket bucket = userBuckets.computeIfAbsent(userId, 
            k -> new TokenBucket(100, 10));
        
        return bucket.tryConsume();
    }
}
```

#### 9. **StickySessionManager.java**
- **AmaÃ§**: Session persistence
- **MantÄ±k**: Cookie veya session ID ile aynÄ± backend'e yÃ¶nlendirir

#### 10. **LoadBalancerMetrics.java**
- **AmaÃ§**: Micrometer metrics (Prometheus integration)
- **Metrics**:
  - `lb_requests_total` - Toplam istek sayÄ±sÄ±
  - `lb_requests_failed` - BaÅŸarÄ±sÄ±z istek sayÄ±sÄ±
  - `lb_active_connections` - Aktif baÄŸlantÄ± sayÄ±sÄ±
  - `lb_response_time` - Response sÃ¼releri

**Custom Metric Ekleme**:
```java
@Component
public class LoadBalancerMetrics {
    
    private final Counter customMetric;
    
    public LoadBalancerMetrics(MeterRegistry registry) {
        this.customMetric = Counter.builder("lb_custom_metric")
            .description("Custom description")
            .register(registry);
    }
    
    public void recordCustomEvent() {
        customMetric.increment();
    }
}
```

**Grafana'da gÃ¶rÃ¼ntÃ¼leme**:
```promql
rate(lb_custom_metric_total[5m])
```

---

## ğŸ§ª Test ve Ã‡alÄ±ÅŸtÄ±rma

### Ä°lk Kurulum

```bash
# 1. Repository'yi clone'la
git clone <repo-url>
cd spectrum-platform

# 2. Setup script'i Ã§alÄ±ÅŸtÄ±r
chmod +x scripts/*.sh
./scripts/setup.sh

# 3. Servisleri baÅŸlat
./scripts/start.sh

# 4. Health check (30-60 saniye bekle)
./scripts/health-check.sh
```

### Load Balancer Test SenaryolarÄ±

#### Test 1: Basic Routing

```bash
# Load balancer Ã¼zerinden kisakes servisine istek
curl http://localhost:8080/kisakes/actuator/health

# Response:
{
  "status": "UP",
  "components": {
    "db": {"status": "UP"},
    "redis": {"status": "UP"}
  }
}
```

#### Test 2: Round Robin DoÄŸrulama

```bash
# 10 istek gÃ¶nder ve hangi instance'Ä±n cevap verdiÄŸini gÃ¶r
for i in {1..10}; do
  curl -s http://localhost:8080/kisakes/actuator/info | jq -r '.app.instance'
done

# Ã‡Ä±ktÄ± (Round Robin):
# kisakes-app-1
# kisakes-app-2
# kisakes-app-1
# kisakes-app-2
# ...
```

#### Test 3: Load Balancing Strategy DeÄŸiÅŸtirme

```bash
# 1. Config deÄŸiÅŸtir
vim infrastructure/load-balancer/src/main/resources/application.yml
# algorithm: LEAST_CONNECTIONS yap

# 2. Rebuild
docker-compose build load-balancer

# 3. Restart
docker-compose restart load-balancer

# 4. Test
for i in {1..20}; do
  curl -s http://localhost:8080/dummy-service/slow-endpoint &
done
wait

# 5. Ä°statistikleri kontrol et
curl http://localhost:8080/admin/status | jq
```

#### Test 4: Circuit Breaker

```bash
# 1. Bir servisi kapat
docker stop kisakes-app-1

# 2. Ä°stekler gÃ¶nder (circuit breaker aÃ§Ä±lana kadar)
for i in {1..10}; do
  curl http://localhost:8080/kisakes/actuator/health
  sleep 1
done

# 3. Circuit breaker state'ini kontrol et
curl http://localhost:8080/admin/circuit-breaker-status | jq

# 4. Servisi tekrar baÅŸlat
docker start kisakes-app-1

# 5. Circuit breaker kapanmasÄ±nÄ± bekle (success threshold kadar baÅŸarÄ±lÄ± istek)
for i in {1..5}; do
  curl http://localhost:8080/kisakes/actuator/health
  sleep 2
done
```

#### Test 5: Health Check

```bash
# 1. Bir servisi unhealthy yap (Ã¶rnek: database baÄŸlantÄ±sÄ±nÄ± kes)
docker pause postgres-db

# 2. Health checker'Ä±n tespit etmesini bekle (5-10 saniye)
sleep 10

# 3. Load balancer status kontrol et
curl http://localhost:8080/admin/status | jq

# Ã‡Ä±ktÄ±:
# {
#   "kisakes": {
#     "totalServers": 2,
#     "healthyCount": 0,  # Ä°kisi de unhealthy
#     "servers": [...]
#   }
# }

# 4. Database'i tekrar baÅŸlat
docker unpause postgres-db

# 5. Recovery'yi izle
watch -n 1 'curl -s http://localhost:8080/admin/status | jq'
```

#### Test 6: Rate Limiting

```bash
# 1. Rate limiting aktif et
vim infrastructure/load-balancer/src/main/resources/application.yml
# rate-limit.enabled: true yap
# rate-limit.requests-per-second: 10

# 2. Rebuild ve restart
docker-compose build load-balancer
docker-compose restart load-balancer

# 3. YÃ¼ksek trafik gÃ¶nder
./scripts/load-test.sh http://localhost:8080/dummy-service/hello 100 20

# 4. 429 Too Many Requests response'larÄ±nÄ± gÃ¶r
```

#### Test 7: Weighted Round Robin

```bash
# 1. AÄŸÄ±rlÄ±klarÄ± deÄŸiÅŸtir
vim infrastructure/load-balancer/src/main/resources/application.yml
# kisakes-app-1: weight: 1
# kisakes-app-2: weight: 3

# 2. Rebuild ve restart
docker-compose build load-balancer
docker-compose restart load-balancer

# 3. Test (app-2 3x daha fazla istek almalÄ±)
for i in {1..40}; do
  curl -s http://localhost:8080/kisakes/actuator/info | jq -r '.app.instance'
done | sort | uniq -c

# Ã‡Ä±ktÄ±:
# 10 kisakes-app-1
# 30 kisakes-app-2
```

#### Test 8: Sticky Sessions

```bash
# 1. Sticky session aktif et
vim infrastructure/load-balancer/src/main/resources/application.yml
# sticky-session.enabled: true

# 2. Rebuild ve restart
docker-compose build load-balancer
docker-compose restart load-balancer

# 3. Cookie ile test
# Ä°lk istek - cookie al
curl -c cookies.txt http://localhost:8080/kisakes/actuator/info

# Sonraki istekler - aynÄ± instance'a gitmeli
for i in {1..10}; do
  curl -b cookies.txt -s http://localhost:8080/kisakes/actuator/info | jq -r '.app.instance'
done

# Hepsi aynÄ± instance dÃ¶ner
```

#### Test 9: Load Test (Performance)

```bash
# Apache Bench ile
sudo apt-get install apache2-utils

# 1000 istek, 50 concurrent
ab -n 1000 -c 50 http://localhost:8080/dummy-service/hello

# SonuÃ§lar:
# - Requests per second
# - Time per request
# - Transfer rate
# - Percentile response times

# Script ile
./scripts/load-test.sh http://localhost:8080/kisakes/actuator/health 5000 100
```

#### Test 10: Monitoring Integration

```bash
# 1. Prometheus'ta metrics kontrol et
open http://localhost:9090/graph

# 2. Queries:
# - rate(http_server_requests_seconds_count[5m])  # Request rate
# - http_server_requests_seconds_max              # Max response time
# - lb_active_connections                         # Active connections

# 3. Grafana dashboard
open http://localhost:3000
# Login: admin / admin123
# Dashboards > Load Balancer Dashboard

# 4. Loki'de loglarÄ± gÃ¶r
# Grafana > Explore > Loki
# Query: {service="load-balancer"}
```

---

## ğŸ”„ DeÄŸiÅŸiklik SenaryolarÄ±

### Senaryo 1: Yeni Mikroservis Ekleme

**AdÄ±mlar**:

1. **Servis OluÅŸtur**:
```bash
cd services
mkdir my-new-service
cd my-new-service
```

2. **pom.xml**:
```xml
<parent>
    <groupId>com.degerli</groupId>
    <artifactId>spectrum-platform</artifactId>
    <version>1.0.0-SNAPSHOT</version>
    <relativePath>../../pom.xml</relativePath>
</parent>

<artifactId>my-new-service</artifactId>
<name>My New Service</name>
```

3. **Dockerfile**:
```dockerfile
FROM eclipse-temurin:21-jre-alpine
WORKDIR /app
COPY target/*.jar app.jar
ENTRYPOINT ["java", "-jar", "app.jar"]
```

4. **docker-compose.yml'e ekle**:
```yaml
  my-new-service-1:
    build:
      context: .
      dockerfile: services/my-new-service/Dockerfile
    container_name: my-new-service-1
    networks:
      - microservices-net
    expose:
      - "8085"
    environment:
      - SERVER_PORT=8085
      - SPRING_PROFILES_ACTIVE=docker
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8085/actuator/health"]
      interval: 10s
      timeout: 5s
      retries: 5
```

5. **Load Balancer'a ekle** (`infrastructure/load-balancer/src/main/resources/application.yml`):
```yaml
loadbalancer:
  services:
    my-new-service:
      algorithm: ROUND_ROBIN
      upstreams:
        - url: http://my-new-service-1:8085
          weight: 1
          max-connections: 100
```

6. **Parent pom.xml'e module ekle**:
```xml
<modules>
    <module>services/my-new-service</module>
</modules>
```

7. **Build ve Deploy**:
```bash
mvn clean package
docker-compose build
docker-compose up -d
./scripts/health-check.sh
```

8. **Test**:
```bash
curl http://localhost:8080/my-new-service/actuator/health
```

### Senaryo 2: Load Balancing AlgoritmasÄ± DeÄŸiÅŸtirme

**Durum**: Servislerinizde farklÄ± iÅŸlem sÃ¼releri var, LEAST_CONNECTIONS kullanmak istiyorsun.

**AdÄ±mlar**:

1. **Config DeÄŸiÅŸtir**:
```bash
vim infrastructure/load-balancer/src/main/resources/application.yml
```

```yaml
loadbalancer:
  services:
    kisakes:
      algorithm: LEAST_CONNECTIONS  # ROUND_ROBIN'den deÄŸiÅŸtir
```

2. **Rebuild (sadece load-balancer)**:
```bash
docker-compose build load-balancer
```

3. **Restart**:
```bash
docker-compose restart load-balancer
```

4. **Test**:
```bash
# YavaÅŸ endpoint'e eÅŸzamanlÄ± istekler gÃ¶nder
for i in {1..10}; do
  curl http://localhost:8080/kisakes/slow-endpoint &
done
wait

# BaÄŸlantÄ± sayÄ±larÄ±nÄ± kontrol et
curl http://localhost:8080/admin/status | jq '.kisakes.servers[] | {url, activeConnections}'
```

5. **Monitor**:
```bash
# Prometheus'ta monitoring
open http://localhost:9090
# Query: lb_active_connections{service="kisakes"}
```

### Senaryo 3: Circuit Breaker Threshold DeÄŸiÅŸtirme

**Durum**: Servisler Ã§ok hÄ±zlÄ± circuit breaker'a giriyor, threshold'u artÄ±rmak istiyorsun.

**AdÄ±mlar**:

1. **Config DeÄŸiÅŸtir**:
```yaml
loadbalancer:
  circuit-breaker:
    enabled: true
    failure-threshold: 10        # 5'ten 10'a Ã§Ä±kar
    success-threshold: 3         # 2'den 3'e Ã§Ä±kar
    timeout-seconds: 120         # 60'tan 120'ye Ã§Ä±kar
```

2. **Rebuild ve Restart**:
```bash
docker-compose build load-balancer
docker-compose restart load-balancer
```

3. **Test**:
```bash
# Bir servisi kapat
docker stop kisakes-app-1

# 10 istek gÃ¶nder (threshold kadar)
for i in {1..10}; do
  curl http://localhost:8080/kisakes/actuator/health
  echo "Request $i"
  sleep 1
done

# Circuit breaker aÃ§Ä±lmalÄ±
curl http://localhost:8080/admin/circuit-breaker-status | jq
```

### Senaryo 4: Rate Limiting Aktif Etme

**Durum**: Production'a geÃ§iyorsun, DDoS korumasÄ± istiyorsun.

**AdÄ±mlar**:

1. **Config**:
```yaml
loadbalancer:
  rate-limit:
    enabled: true
    requests-per-second: 100
    burst-capacity: 200
```

2. **Rebuild ve Restart**:
```bash
docker-compose build load-balancer
docker-compose restart load-balancer
```

3. **Test**:
```bash
# YÃ¼ksek trafik gÃ¶nder
./scripts/load-test.sh http://localhost:8080/dummy-service/hello 1000 100

# 429 response'larÄ±nÄ± gÃ¶r
```

4. **Per-User Rate Limiting (Custom)**:
```java
// RateLimiter.java'da deÄŸiÅŸiklik
public boolean allowRequest(HttpServletRequest request) {
    String userId = request.getHeader("X-User-ID");
    if (userId == null) userId = "anonymous";
    
    TokenBucket bucket = userBuckets.computeIfAbsent(userId, 
        k -> new TokenBucket(100, 10));
    
    return bucket.tryConsume();
}
```

### Senaryo 5: Database Migration Ekleme

**Durum**: `urls` tablosuna yeni bir kolon eklemek istiyorsun.

**AdÄ±mlar**:

1. **Yeni Liquibase Changeset**:
```bash
vim services/kisakes/src/main/resources/db/changelog/changes/003-add-expiry-date.yaml
```

```yaml
databaseChangeLog:
  - changeSet:
      id: 003-add-expiry-date
      author: yourname
      changes:
        - addColumn:
            tableName: urls
            columns:
              - column:
                  name: expiry_date
                  type: timestamp
                  constraints:
                    nullable: true
```

2. **Master'a Ekle**:
```yaml
# db.changelog-master.yaml
  - include:
      file: db/changelog/changes/003-add-expiry-date.yaml
```

3. **Entity GÃ¼ncelle**:
```java
@Entity
public class Url {
    // ... existing fields ...
    
    @Column(name = "expiry_date")
    private LocalDateTime expiryDate;
}
```

4. **Rebuild ve Restart**:
```bash
mvn clean package
docker-compose build kisakes-app-1 kisakes-app-2
docker-compose restart kisakes-app-1

# NOT: kisakes-app-2'de Liquibase disabled, restart gerekmez
```

5. **Verify**:
```bash
docker exec -it postgres-db psql -U admin -d kisakes
\d urls
# expiry_date kolonunu gÃ¶receksin
```

### Senaryo 6: Prometheus Scrape Interval DeÄŸiÅŸtirme

**Durum**: Daha sÄ±k metric toplamak istiyorsun.

**AdÄ±mlar**:

1. **Config DeÄŸiÅŸtir**:
```bash
vim infrastructure/monitoring/prometheus/prometheus.yml
```

```yaml
global:
  scrape_interval: 5s      # 15s'den 5s'ye dÃ¼ÅŸÃ¼r
  evaluation_interval: 5s
```

2. **Restart**:
```bash
docker-compose restart prometheus
```

3. **Verify**:
```bash
# Prometheus UI'da Targets'Ä± kontrol et
open http://localhost:9090/targets
# Last Scrape kolonu - 5 saniyede bir update olmalÄ±
```

### Senaryo 7: Grafana Dashboard Ekleme

**AdÄ±mlar**:

1. **Dashboard JSON OluÅŸtur**:
```bash
vim infrastructure/monitoring/grafana/dashboards/load-balancer-dashboard.json
```

2. **Provisioning Config**:
```bash
vim infrastructure/monitoring/grafana/dashboards/dashboard.yml
```

```yaml
apiVersion: 1

providers:
  - name: 'Load Balancer'
    folder: 'Custom'
    type: file
    options:
      path: /etc/grafana/provisioning/dashboards
```

3. **Restart Grafana**:
```bash
docker-compose restart grafana
```

4. **Dashboard Import**:
- Grafana UI'da dashboards'a git
- Otomatik yÃ¼klenmiÅŸ olmalÄ±

### Senaryo 8: SSL/TLS Ekleme

**AdÄ±mlar**:

1. **Keystore OluÅŸtur**:
```bash
keytool -genkeypair -alias spectrum-lb -keyalg RSA -keysize 2048 \
  -storetype PKCS12 -keystore keystore.p12 -validity 3650 \
  -storepass changeit
```

2. **Keystore'u Kopyala**:
```bash
cp keystore.p12 infrastructure/load-balancer/src/main/resources/
```

3. **Config**:
```yaml
# application.yml
server:
  port: 8443
  ssl:
    enabled: true
    key-store: classpath:keystore.p12
    key-store-password: changeit
    key-store-type: PKCS12

loadbalancer:
  ssl:
    enabled: true
```

4. **docker-compose.yml Port Mapping**:
```yaml
load-balancer:
  ports:
    - "8080:8080"
    - "8443:8443"  # HTTPS
```

5. **Rebuild ve Restart**:
```bash
docker-compose build load-balancer
docker-compose restart load-balancer
```

6. **Test**:
```bash
curl -k https://localhost:8443/actuator/health
```

### Senaryo 9: Blue-Green Deployment

**Durum**: Zero-downtime deployment yapmak istiyorsun.

**AdÄ±mlar**:

1. **Yeni Version Deploy Et (Green)**:
```bash
# Yeni version'Ä± build et
mvn clean package -DskipTests

# Sadece bir instance'Ä± gÃ¼ncelle (Green)
docker-compose build kisakes-app-2
docker-compose stop kisakes-app-2
docker-compose up -d kisakes-app-2
```

2. **Health Check**:
```bash
# Green instance'Ä±n healthy olmasÄ±nÄ± bekle
watch -n 1 'curl -s http://kisakes-app-2:8082/actuator/health'
```

3. **Load Balancer'da Green'i Aktif Et**:
```bash
# Admin API kullanarak
curl -X POST http://localhost:8080/admin/servers/kisakes/enable \
  -d "url=http://kisakes-app-2:8082"
```

4. **Blue'yu GÃ¼ncelle**:
```bash
docker-compose build kisakes-app-1
docker-compose stop kisakes-app-1
docker-compose up -d kisakes-app-1
```

5. **Verify**:
```bash
./scripts/health-check.sh
curl http://localhost:8080/admin/status | jq
```

### Senaryo 10: Connection Pool Boyutu DeÄŸiÅŸtirme

**Durum**: YÃ¼ksek trafikte connection pool yetersiz.

**AdÄ±mlar**:

1. **Load Balancer Config**:
```yaml
loadbalancer:
  services:
    kisakes:
      upstreams:
        - url: http://kisakes-app-1:8081
          max-connections: 200  # 100'den 200'e Ã§Ä±kar
```

2. **Backend HikariCP Config** (kisakes service):
```yaml
spring:
  datasource:
    hikari:
      maximum-pool-size: 50  # 20'den 50'ye Ã§Ä±kar
      minimum-idle: 10
      connection-timeout: 30000
```

3. **Rebuild ve Restart**:
```bash
# Load balancer
docker-compose build load-balancer
docker-compose restart load-balancer

# Kisakes
docker-compose build kisakes-app-1 kisakes-app-2
docker-compose restart kisakes-app-1 kisakes-app-2
```

4. **Test**:
```bash
# YÃ¼ksek concurrent requests
./scripts/load-test.sh http://localhost:8080/kisakes/api/endpoint 10000 100
```

---

## ğŸ” Troubleshooting

### Problem 1: Load Balancer BaÅŸlamÄ±yor

**Semptom**:
```bash
docker logs load-balancer
# Error: Cannot connect to backend services
```

**Ã‡Ã¶zÃ¼m**:
```bash
# 1. Backend servislerin healthy olduÄŸunu kontrol et
./scripts/health-check.sh

# 2. Network kontrolÃ¼
docker network inspect microservices-net

# 3. DNS Ã§Ã¶zÃ¼mleme testi
docker exec load-balancer ping kisakes-app-1

# 4. Restart order
docker-compose stop
docker-compose up -d postgres-db redis-cache
sleep 10
docker-compose up -d kisakes-app-1 kisakes-app-2 dummy-service-1 dummy-service-2
sleep 20
docker-compose up -d load-balancer
```

### Problem 2: Circuit Breaker SÃ¼rekli AÃ§Ä±k

**Semptom**:
```bash
curl http://localhost:8080/kisakes/actuator/health
# 503 Service Unavailable - Circuit Breaker OPEN
```

**Ã‡Ã¶zÃ¼m**:
```bash
# 1. Backend servisleri kontrol et
docker ps | grep kisakes

# 2. Backend loglarÄ±nÄ± incele
docker logs kisakes-app-1
docker logs kisakes-app-2

# 3. Manuel circuit breaker reset
curl -X POST http://localhost:8080/admin/circuit-breaker/reset

# 4. Threshold'u geÃ§ici olarak artÄ±r
# application.yml: failure-threshold: 100
docker-compose restart load-balancer
```

### Problem 3: Health Check Fail

**Semptom**:
```bash
./scripts/health-check.sh
# âœ— kisakes-app-1 (unhealthy)
```

**Ã‡Ã¶zÃ¼m**:
```bash
# 1. Container status
docker ps -a | grep kisakes-app-1

# 2. Logs
docker logs kisakes-app-1 --tail 100

# 3. Health endpoint manuel test
docker exec kisakes-app-1 curl http://localhost:8081/actuator/health

# 4. Database baÄŸlantÄ±sÄ±
docker exec -it postgres-db psql -U admin -d kisakes -c "SELECT 1;"

# 5. Redis baÄŸlantÄ±sÄ±
docker exec redis-cache redis-cli ping

# 6. Network
docker exec kisakes-app-1 ping postgres-db
```

### Problem 4: YÃ¼ksek Latency

**Semptom**:
```bash
./scripts/load-test.sh
# Average response time: 5000ms (Ã§ok yÃ¼ksek)
```

**Diagnosis**:
```bash
# 1. Prometheus'ta response time
open http://localhost:9090
# Query: http_server_requests_seconds_max{job="load-balancer"}

# 2. Load balancer metrics
curl http://localhost:8080/actuator/metrics/http.server.requests | jq

# 3. Database slow queries
docker exec postgres-db psql -U admin -d kisakes -c "
  SELECT query, mean_exec_time 
  FROM pg_stat_statements 
  ORDER BY mean_exec_time DESC 
  LIMIT 10;"

# 4. Connection pool
curl http://localhost:8080/admin/status | jq '.kisakes.servers[] | {url, activeConnections, maxConnections}'
```

**Ã‡Ã¶zÃ¼mler**:
```bash
# A. Database indexler
docker exec -it postgres-db psql -U admin -d kisakes
CREATE INDEX idx_urls_short_code ON urls(short_code);

# B. Redis cache aktif et
# application.yml'de caching config

# C. Connection pool artÄ±r (yukarÄ±da anlatÄ±ldÄ±)

# D. Load balancing stratejisini deÄŸiÅŸtir
# LEAST_CONNECTIONS kullan
```

### Problem 5: 429 Too Many Requests (Rate Limiting)

**Semptom**:
```bash
curl http://localhost:8080/kisakes/api/endpoint
# 429 Too Many Requests
```

**Ã‡Ã¶zÃ¼m**:
```bash
# 1. Rate limit config kontrol
vim infrastructure/load-balancer/src/main/resources/application.yml
# rate-limit.enabled: false veya threshold'u artÄ±r

# 2. GeÃ§ici olarak disable et
# Admin API (eÄŸer implement edilmiÅŸse)
curl -X POST http://localhost:8080/admin/rate-limit/disable

# 3. Restart
docker-compose restart load-balancer
```

### Problem 6: Database Connection Pool Exhausted

**Semptom**:
```bash
docker logs kisakes-app-1
# ERROR: HikariPool - Connection is not available
```

**Ã‡Ã¶zÃ¼m**:
```bash
# 1. Pool size artÄ±r
vim services/kisakes/src/main/resources/application-docker.yml
```

```yaml
spring:
  datasource:
    hikari:
      maximum-pool-size: 50
      minimum-idle: 20
      connection-timeout: 60000
      idle-timeout: 600000
      max-lifetime: 1800000
```

```bash
# 2. Rebuild
docker-compose build kisakes-app-1 kisakes-app-2
docker-compose restart kisakes-app-1 kisakes-app-2

# 3. PostgreSQL max_connections artÄ±r
docker exec -it postgres-db bash
echo "max_connections = 200" >> /var/lib/postgresql/data/postgresql.conf
docker-compose restart postgres-db
```

### Problem 7: Memory Leak

**Semptom**:
```bash
docker stats
# load-balancer: 2GB+ memory kullanÄ±mÄ±
```

**Diagnosis**:
```bash
# 1. Heap dump al
docker exec load-balancer jcmd 1 GC.heap_dump /tmp/heap.hprof
docker cp load-balancer:/tmp/heap.hprof ./heap.hprof

# 2. VisualVM veya Eclipse MAT ile analiz et

# 3. Thread dump
docker exec load-balancer jstack 1 > threads.txt
```

**Ã‡Ã¶zÃ¼mler**:
```bash
# A. JVM heap size artÄ±r
# Dockerfile'da
ENV JAVA_OPTS="-Xms512m -Xmx2048m"

# B. GC tuning
ENV JAVA_OPTS="-XX:+UseG1GC -XX:MaxGCPauseMillis=200"

# C. Memory leak varsa fix'le (kod deÄŸiÅŸikliÄŸi gerekebilir)
```

### Problem 8: Prometheus Metrics ToplanmÄ±yor

**Semptom**:
```bash
open http://localhost:9090/targets
# All targets: DOWN
```

**Ã‡Ã¶zÃ¼m**:
```bash
# 1. Network connectivity
docker exec prometheus ping load-balancer
docker exec prometheus curl http://load-balancer:8080/actuator/prometheus

# 2. Actuator endpoints exposed mi?
docker exec load-balancer curl http://localhost:8080/actuator
# prometheus endpoint'i gÃ¶rmeli

# 3. Config kontrol
docker exec prometheus cat /etc/prometheus/prometheus.yml

# 4. Restart
docker-compose restart prometheus
```

### Problem 9: Grafana Dashboards Yok

**Semptom**:
```bash
# Grafana'da dashboard gÃ¶rÃ¼nmÃ¼yor
```

**Ã‡Ã¶zÃ¼m**:
```bash
# 1. Provisioning klasÃ¶rÃ¼nÃ¼ kontrol et
ls -la infrastructure/monitoring/grafana/dashboards/

# 2. Volume mount doÄŸru mu?
docker inspect grafana | grep Mounts -A 20

# 3. Grafana loglarÄ±
docker logs grafana

# 4. Manuel import
# Grafana UI > Dashboards > Import > Upload JSON
```

### Problem 10: Docker Compose Build HatasÄ±

**Semptom**:
```bash
docker-compose build
# ERROR: Cannot locate specified Dockerfile
```

**Ã‡Ã¶zÃ¼m**:
```bash
# 1. Context ve dockerfile path kontrol
cat docker-compose.yml | grep -A 5 "build:"

# 2. Dockerfile var mÄ±?
ls -la services/kisakes/Dockerfile
ls -la infrastructure/load-balancer/Dockerfile

# 3. Maven build Ã¶nce Ã§alÄ±ÅŸmalÄ±
mvn clean package -DskipTests

# 4. Cache temizle
docker-compose build --no-cache
```

---

## ğŸ“Š Monitoring ve Observability

### Prometheus Queries

**Request Rate**:
```promql
rate(http_server_requests_seconds_count{job="load-balancer"}[5m])
```

**Average Response Time**:
```promql
rate(http_server_requests_seconds_sum[5m]) 
/ 
rate(http_server_requests_seconds_count[5m])
```

**Error Rate**:
```promql
rate(http_server_requests_seconds_count{status=~"5.."}[5m])
```

**Active Connections**:
```promql
lb_active_connections{service="kisakes"}
```

**Circuit Breaker State**:
```promql
lb_circuit_breaker_state{service="kisakes"}
```

### Loki Queries

**Load Balancer Errors**:
```logql
{service="load-balancer"} |= "ERROR"
```

**Slow Requests**:
```logql
{service="load-balancer"} | json | duration > 1000
```

**Circuit Breaker Events**:
```logql
{service="load-balancer"} |= "Circuit Breaker" |= "OPEN"
```

---

## ğŸš€ Production Checklist

### GÃ¼venlik

- [ ] Default ÅŸifreleri deÄŸiÅŸtir (PostgreSQL, Redis, Grafana)
- [ ] SSL/TLS aktif et
- [ ] Rate limiting aktif et
- [ ] Database ÅŸifre ÅŸifreleme (vault kullan)
- [ ] Secrets management (Docker secrets veya Kubernetes secrets)
- [ ] Network policies (firewall kurallarÄ±)
- [ ] Container security scanning (Trivy, Clair)

### Performance

- [ ] Connection pool'larÄ± optimize et
- [ ] JVM heap size ayarla
- [ ] Database indexler oluÅŸtur
- [ ] Redis caching stratejisi belirle
- [ ] Load test yap ve bottleneck'leri tespit et
- [ ] Auto-scaling stratejisi belirle

### Monitoring

- [ ] Alert kurallarÄ± tanÄ±mla (Prometheus Alertmanager)
- [ ] Dashboard'lar hazÄ±rla
- [ ] Log retention policy belirle
- [ ] Metrics retention policy belirle
- [ ] On-call rotation belirle

### Deployment

- [ ] CI/CD pipeline kur
- [ ] Blue-green deployment stratejisi
- [ ] Rollback planÄ±
- [ ] Database migration stratejisi
- [ ] Backup stratejisi
- [ ] Disaster recovery planÄ±

### Documentation

- [ ] API documentation (Swagger/OpenAPI)
- [ ] Runbook'lar hazÄ±rla
- [ ] Architecture decision records (ADR)
- [ ] Onboarding dokÃ¼mantasyonu

---

## ğŸ“š Ek Kaynaklar

### Komut Cheatsheet

```bash
# Servis baÅŸlatma
./scripts/start.sh

# Servis durdurma
./scripts/stop.sh

# Health check
./scripts/health-check.sh

# Load test
./scripts/load-test.sh [URL] [REQUESTS] [CONCURRENCY]

# LoglarÄ± gÃ¶rÃ¼ntÃ¼leme
./scripts/logs.sh [SERVICE_NAME]

# Scale up/down
./scripts/scale.sh kisakes 3

# Restart
./scripts/restart.sh [SERVICE_NAME]

# Build
docker-compose build [SERVICE_NAME]

# Logs
docker-compose logs -f [SERVICE_NAME]

# Exec
docker exec -it [CONTAINER] bash

# Stats
docker stats

# Cleanup
./scripts/clean.sh
```

### API Endpoints

**Load Balancer**:
- `GET /actuator/health` - Health check
- `GET /actuator/metrics` - Metrics
- `GET /actuator/prometheus` - Prometheus metrics
- `GET /admin/status` - Service status
- `GET /admin/features` - Feature flags
- `POST /admin/circuit-breaker/reset` - Reset circuit breaker

**Kisakes Service**:
- `GET /kisakes/actuator/health` - Health check
- `GET /kisakes/actuator/metrics` - Metrics
- `GET /kisakes/api/urls` - URL listesi
- `POST /kisakes/api/urls` - Yeni URL oluÅŸtur

**Monitoring**:
- `http://localhost:9090` - Prometheus UI
- `http://localhost:3000` - Grafana UI
- `http://localhost:3100/ready` - Loki health

---

## ğŸ“ SonuÃ§

Bu dokÃ¼mantasyon, Spectrum Platform'un tÃ¼m bileÅŸenlerini, konfigÃ¼rasyonlarÄ±nÄ± ve kullanÄ±m senaryolarÄ±nÄ± kapsamaktadÄ±r. 

**Ã–nemli Notlar**:
1. Her deÄŸiÅŸiklikten sonra ilgili servisleri rebuild ve restart et
2. Test et - production'a gÃ¶ndermeden Ã¶nce tÃ¼m senaryolarÄ± test et
3. Monitoring - deÄŸiÅŸikliklerin etkisini Prometheus ve Grafana'da izle
4. DokÃ¼mante et - yaptÄ±ÄŸÄ±n deÄŸiÅŸiklikleri kaydet

**Destek iÃ§in**:
- GitHub Issues
- Documentation: `/docs`
- Examples: `/examples`

---

**Version**: 1.0.0  
**Last Updated**: 2024  
**Author**: Spectrum Platform Team